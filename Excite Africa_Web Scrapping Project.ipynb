{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c01199a8-1573-4a34-bfd0-43c6e1384400",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The challenge involves extracting specific information from a target website https://www.scrapethissite.com/pages/frames/, \n",
    "# you are to get the name of the turtle and the bio in a csv file . You are encouraged to utilize any programming language \n",
    "# and libraries/tools of your choice.\n",
    "\n",
    "#Solutions\n",
    "\n",
    "# I inported the necessay libries as listed below\n",
    "# checked for the source oo check if there are any external links or references to page, https://www.scrapethissite.com/pages/frames/\n",
    "# Viewed Page Source\"  <a href=\"https://en.wikipedia.org/wiki/List_of_Testudines_families\" class=\"data-attribution\" target=\"_blank\">https://en.wikipedia.org/wiki/List_of_Testudines_families</a>\n",
    "# with this i know the page t extract from and proceeded with other necessary codes\n",
    "# conclusion shows the list in csv of turtle name embeded in the page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1475b558-5b81-4f6d-b4f7-e0c6ded4dc82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV File Content:\n",
      "                                          Turtle Name\n",
      "0   Cryptodira  11 families, 74 genera, over 200 ...\n",
      "1                     CarettochelyidaeBoulenger, 1887\n",
      "2                              CheloniidaeOppel, 1811\n",
      "3                               ChelydridaeGray, 1831\n",
      "4                            DermatemydidaeGray, 1870\n",
      "5                       DermochelyidaeFitzinger, 1843\n",
      "6                            EmydidaeRafinesque, 1815\n",
      "7                           GeoemydidaeTheobald, 1868\n",
      "8                          KinosternidaeAgassiz, 1857\n",
      "9                            PlatysternidaeGray, 1869\n",
      "10                           TestudinidaeBatsch, 1788\n",
      "11                        TrionychidaeFitzinger, 1826\n",
      "12  Pleurodira  3 families, 16 genera, over 60 sp...\n",
      "13                                 ChelidaeGray, 1831\n",
      "14                            PelomedusidaeCope, 1868\n",
      "15                           PodocnemididaeGray, 1869\n",
      "16                                   Scrape This Site\n",
      "17                                            Sandbox\n",
      "18                                            Lessons\n",
      "19                                                FAQ\n",
      "20                                              Login\n",
      "\n",
      "List of Turtle Names:\n",
      "Cryptodira  11 families, 74 genera, over 200 species\n",
      "CarettochelyidaeBoulenger, 1887\n",
      "CheloniidaeOppel, 1811\n",
      "ChelydridaeGray, 1831\n",
      "DermatemydidaeGray, 1870\n",
      "DermochelyidaeFitzinger, 1843\n",
      "EmydidaeRafinesque, 1815\n",
      "GeoemydidaeTheobald, 1868\n",
      "KinosternidaeAgassiz, 1857\n",
      "PlatysternidaeGray, 1869\n",
      "TestudinidaeBatsch, 1788\n",
      "TrionychidaeFitzinger, 1826\n",
      "Pleurodira  3 families, 16 genera, over 60 species\n",
      "ChelidaeGray, 1831\n",
      "PelomedusidaeCope, 1868\n",
      "PodocnemididaeGray, 1869\n",
      "Scrape This Site\n",
      "Sandbox\n",
      "Lessons\n",
      "FAQ\n",
      "Login\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import csv\n",
    "import pandas as pd\n",
    "from urllib.parse import urljoin\n",
    "\n",
    "# Function to extract turtle names from the Wikipedia page\n",
    "def extract_turtle_names_from_wikipedia(url):\n",
    "    response = requests.get(url)\n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "    turtle_names = []\n",
    "    tables = soup.find_all('table', class_='wikitable')\n",
    "    \n",
    "    for table in tables:\n",
    "        rows = table.find_all('tr')\n",
    "        for row in rows:\n",
    "            cells = row.find_all('td')\n",
    "            if cells:\n",
    "                name = cells[0].text.strip()  # Get turtle name from the first cell \n",
    "                turtle_names.append(name)\n",
    "    \n",
    "    return turtle_names\n",
    "\n",
    "# Function to extract turtle names from the second link (ScrapeThisSite)\n",
    "def extract_turtle_names_from_scrapethissite(url):\n",
    "    response = requests.get(url)\n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "    turtle_names = []\n",
    "    \n",
    "    # Find all frames in the page (frames may contain the data we need)\n",
    "    frames = soup.find_all('iframe')\n",
    "    \n",
    "    # Iterate through each iframe to scrape relevant data (assuming the data is embedded in one of the frames)\n",
    "    for frame in frames:\n",
    "        frame_url = frame['src']\n",
    "        \n",
    "        # Convert relative URL to absolute URL\n",
    "        full_url = urljoin(url, frame_url)  # This ensures the correct URL format\n",
    "        frame_response = requests.get(full_url)\n",
    "        frame_soup = BeautifulSoup(frame_response.content, 'html.parser')\n",
    "        \n",
    "        # You may need to adjust this part based on the actual structure of the page\n",
    "        # Let's assume the turtle names are inside a list or table with a specific class\n",
    "        names = frame_soup.find_all('li')  # Example of extracting data inside <li> tags\n",
    "        for name in names:\n",
    "            turtle_names.append(name.text.strip())\n",
    "    \n",
    "    return turtle_names\n",
    "\n",
    "# Define URLs for both pages\n",
    "wikipedia_url = 'https://en.wikipedia.org/wiki/List_of_Testudines_families'\n",
    "scrapethissite_url = 'https://www.scrapethissite.com/pages/frames/'\n",
    "\n",
    "# Extract turtle names from both URLs\n",
    "turtle_names_wikipedia = extract_turtle_names_from_wikipedia(wikipedia_url)\n",
    "turtle_names_scrapethissite = extract_turtle_names_from_scrapethissite(scrapethissite_url)\n",
    "\n",
    "# Combine the turtle names from both sources\n",
    "combined_turtle_names = turtle_names_wikipedia + turtle_names_scrapethissite\n",
    "\n",
    "# Define the CSV filename\n",
    "filename = 'combined_turtle_names.csv'\n",
    "\n",
    "# Save the combined turtle names to a CSV file\n",
    "with open(filename, 'w', newline='') as csvfile:\n",
    "    csvwriter = csv.writer(csvfile)\n",
    "    csvwriter.writerow(['Turtle Name'])  # Write the header\n",
    "    \n",
    "    for name in combined_turtle_names:\n",
    "        csvwriter.writerow([name])  # Write each name to the CSV file\n",
    "\n",
    "# Read the CSV file to verify its content\n",
    "try:\n",
    "    df = pd.read_csv(filename, encoding='ISO-8859-1')\n",
    "    \n",
    "    # Display the content of the CSV file\n",
    "    print(\"CSV File Content:\")\n",
    "    print(df)\n",
    "    \n",
    "    # Print the list of turtle names from the CSV\n",
    "    if 'Turtle Name' in df.columns:\n",
    "        print(\"\\nList of Turtle Names:\")\n",
    "        for name in df['Turtle Name']:\n",
    "            print(name)\n",
    "    else:\n",
    "        print(\"The column 'Turtle Name' does not exist in the CSV file.\")\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred while reading the CSV file: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16045dfb-9ca1-4cb6-90be-55c495ae58f8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
